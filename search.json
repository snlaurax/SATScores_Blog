[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Educational Equity and SAT Scores\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/Topics.html",
    "href": "posts/Topics.html",
    "title": "Educational Equity and SAT Scores",
    "section": "",
    "text": "title: “First File” description: “Testing Quarto” author: Laura Lu date: “07/26/2023” date-modified: “07/26/2023”"
  },
  {
    "objectID": "posts/Topics.html#results",
    "href": "posts/Topics.html#results",
    "title": "Educational Equity and SAT Scores",
    "section": "Results",
    "text": "Results\n\nAverage Total Number of Test Takers in Each State\nI begin with investigating whether or not there is a geographical variance in the number of test takers. Understanding geographical variance in the number of test-takers can provide insight into the number of resources in each state which can perpetuate educational equity.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Group the DataFrame by 'State' and calculate the average 'Total Test-takers'\navg_total = df.groupby('State.Code')['Total.Test-takers'].mean()\n\n# Sort the results in descending order\navg_total = avg_total.sort_values(ascending=False)\n\nplt.figure(figsize=(12, 6)) \nplt.bar(avg_total.index, avg_total)\n\nplt.xlabel('State')\nplt.ylabel('Average Total Test Takers')\nplt.title('Average Total Test Takers Across States (2005-2015)')\n\nplt.xticks(rotation=90)\n\nplt.tight_layout() \nplt.show()\n\n\n\n\nAbove is a graph that showcases the average total test takers across States over the decade between 2005 to 2015. California has the most number of test takers while Wyoming, South Dakota and North Dakota have the least number of test takers. This suggests that there is lower test participation in these states. States with a denser population seem to have more test takers. States with higher population densities often have larger and more diverse school systems, which can lead to increased test participation due to higher student enrollments.\n\n\nNumber of Test Takers in Each Income Bracket\n\n# Calculate the total number of test-takers in each income range\ntotal_20_40k = df['Family Income.Between 20-40k.Test-takers'].sum()\ntotal_40_60k = df['Family Income.Between 40-60k.Test-takers'].sum()\ntotal_60_80k = df['Family Income.Between 60-80k.Test-takers'].sum()\ntotal_80_100k = df['Family Income.Between 80-100k.Test-takers'].sum()\ntotal_less_than_20k = df['Family Income.Less than 20k.Test-takers'].sum()\ntotal_more_than_100k = df['Family Income.More than 100k.Test-takers'].sum()\n\n# Create a bar graph\nbracket = ['&lt; 20k', '20-40k', '40-60k', '60-80k', '80-100k', '&gt;100k']\ncount = [total_less_than_20k, total_20_40k, total_40_60k, total_60_80k, total_80_100k, total_more_than_100k]\n\nplt.bar(bracket, count)\n\nplt.xlabel('Family Income Range')\nplt.ylabel('Total Test-takers')\nplt.title('Total Test-takers in Each Family Income Range')\n\nplt.show()\n\n\n\n\nThere are more test takers in the &gt;100k range than any other range. It would be interesting to later investigate how well students in the 20-40k income bracket perform relative to 80-100k.\n\n\nAverage Combined Score Across States for Each Year\n\n# Calculate the combined score by adding 'Total.Verbal' and 'Total.Math' for each row\ndf['Combined_Score'] = df['Total.Verbal'] + df['Total.Math']\n\n# Group the DataFrame by 'year' and calculate the average combined score for each year\naverage_combined_score = df.groupby('Year')['Combined_Score'].mean()\n\n# Plot the data on a line graph\nplt.figure(figsize=(6, 4))  # Set the size of the figure (width, height)\n\n# Plot the average combined score against the years\nplt.plot(average_combined_score.index, average_combined_score, marker='o', linestyle='-', color='b')\n\nplt.xlabel('Year')\nplt.ylabel('Average Combined Score')\nplt.title('Average Combined Score Across States for Each Year')\n\nplt.grid(True) \nplt.tight_layout()  \nplt.show()\n\n\n\n\nThe average combined score across states for each year was overall increasing between 2005 to 2010 however there was a significant dip in the score after 2010 to 2011 and since then, the average combined score has not recovered to the same score as prior to 2010. According to Yale Daily News (https://yaledailynews.com/blog/2003/11/19/class-of-2010-to-take-on-new-sat-format/), after the 2010 SAT’s, the SATs added the essay section.\n\n\nAverage Combined GPA Across States for Each Year\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Assuming you have loaded the SAT Scores dataset into a DataFrame called 'df'\n# Make sure 'df' contains columns named 'year', 'Academic Subjects.English.Average GPA', and 'Academic Subjects.Mathematics.Average GPA'\n\n# Calculate the combined GPA by adding 'Academic Subjects.English.Average GPA' and 'Academic Subjects.Mathematics.Average GPA' for each row\ndf['Combined_GPA'] = df['Academic Subjects.English.Average GPA'] + df['Academic Subjects.Mathematics.Average GPA']\n\n# Group the DataFrame by 'year' and calculate the average combined GPA for each year\naverage_combined_gpa = df.groupby('Year')['Combined_GPA'].mean()\n\n# Plot the data on a line graph\nplt.figure(figsize=(8, 4))  # Set the size of the figure (width, height)\n\nplt.plot(average_combined_gpa.index, average_combined_gpa, marker='o', linestyle='-', color='b')\n\nplt.xlabel('Year')\nplt.ylabel('Average Combined GPA')\nplt.title('Average Combined GPA Across States for Each Year')\n\nplt.grid(True)  \nplt.tight_layout()\nplt.show()\n\n\n\n\nThe average combined GPA increases over the years between 2005 to 2015. The increasing trend in the average combined GPA might suggest that students, on average, are achieving higher academic performance over time. On the other hand, this may also have negative implications that I have personally felt during my application process. Inflated grades may have lead to increased competitiveness in the college application process which can also have profound effects on physical and mental health.\n\n\nCase Analysis\nThe code counts the number of positive words (pos) and negative words (neg) in the tokenized text. The sentiment analysis was performed using the VADER (Valence Aware Dictionary and Sentiment Reasoner), which is a pre-trained model for sentiment analysis in natural language processing.\nThe VADER lexicon assigns a sentiment score to each word that measures its positivity, negativity, and neutrality. The polarity_scores() function returns a dictionary with different scores, which represents the overall sentiment of the given word. By iterating through each word in the tokenized text and calculating its score, the code determines whether each word is considered positive or negative. The purpose of checking the number of positive and negative words is to get a rough idea of the overall sentiment of the text."
  },
  {
    "objectID": "posts/Topics.html#discussion",
    "href": "posts/Topics.html#discussion",
    "title": "Educational Equity and SAT Scores",
    "section": "Discussion",
    "text": "Discussion\n\nTotal Test Takers in Family Income Range in Highest and Lowest Test Participating States\n\nTotal Test Takers in Each Family Income Range in California\n\n# Filter the data for California\ncalifornia_data = df[df['State.Name'] == 'California']\n\n# Calculate the total test takers in each family income range\ntotal_test_takers = california_data['Total.Test-takers'].sum()\ntest_takers_20_40k = california_data['Family Income.Between 20-40k.Test-takers'].sum()\ntest_takers_40_60k = california_data['Family Income.Between 40-60k.Test-takers'].sum()\ntest_takers_60_80k = california_data['Family Income.Between 60-80k.Test-takers'].sum()\ntest_takers_80_100k = california_data['Family Income.Between 80-100k.Test-takers'].sum()\ntest_takers_less_than_20k = california_data['Family Income.Less than 20k.Test-takers'].sum()\ntest_takers_more_than_100k = california_data['Family Income.More than 100k.Test-takers'].sum()\n\n# Create a bar graph\nbrackets = ['&lt; 20k','20-40k', '40-60k', '60-80k', '80-100k', '&gt;100k']\ncount = [test_takers_less_than_20k, test_takers_20_40k, test_takers_40_60k, test_takers_60_80k, test_takers_80_100k, test_takers_more_than_100k]\n\nplt.bar(brackets, count)\n\nplt.xlabel('Family Income Range')\nplt.ylabel('Total Test Takers')\nplt.title('Total Test Takers in Each Family Income Range in California')\n\nplt.tight_layout()  # Adjusts the layout to prevent overlapping of labels\nplt.show()\n\n\n\n\nThe most common test takers in California are from households that earn more than 100k per year. This suggests that California has a larger proportion of affluent families participating in standardized testing compared to the rest of the country. More study needs to be conducted into variance within the state itself, and how on a local level that certain areas or school districts have a higher concentration of affluent test takers compared to others and thus, higher SAT scores.\n\n\nTotal Test Takers in Each Family Income Range in Virginia\n\n# Filter the data for California\nVirginia = df[df['State.Name'] == 'Virginia']\n\n# Calculate the total test takers in each family income range\ntotal_test_takers = Virginia['Total.Test-takers'].sum()\ntest_takers_20_40k = Virginia['Family Income.Between 20-40k.Test-takers'].sum()\ntest_takers_40_60k = Virginia['Family Income.Between 40-60k.Test-takers'].sum()\ntest_takers_60_80k = Virginia['Family Income.Between 60-80k.Test-takers'].sum()\ntest_takers_80_100k = Virginia['Family Income.Between 80-100k.Test-takers'].sum()\ntest_takers_less_than_20k = Virginia['Family Income.Less than 20k.Test-takers'].sum()\ntest_takers_more_than_100k = Virginia['Family Income.More than 100k.Test-takers'].sum()\n\n# Create a bar graph\nbrackets = ['&lt; 20k','20-40k', '40-60k', '60-80k', '80-100k', '&gt;100k']\ncount = [test_takers_less_than_20k, test_takers_20_40k, test_takers_40_60k, test_takers_60_80k, test_takers_80_100k, test_takers_more_than_100k]\n\nplt.bar(brackets, count)\n\nplt.xlabel('Family Income Range')\nplt.ylabel('Total Test Takers')\nplt.title('Total Test Takers in Each Family Income Range in Virginia')\n\nplt.tight_layout()  # Adjusts the layout to prevent overlapping of labels\nplt.show()\n\n\n\n\nDespite Virginia having the least amount of test takers in the nation, most of its test takers also are from families with more than 100k income levels. It apears that even though there are less test takers, the percentage of test takers that are from higher income families remains consistent between high numbers of participants and low number of participants in each state. This might suggest that there is less geographical variance in comparison to income variance when it comes to performance on the SAT.\n\n\n\nAverage Combined Scores in California\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter the data for California\ncalifornia_data = df[df['State.Name'] == 'California']\n\n# Calculate the combined score by adding 'Total.Verbal' and 'Total.Math' for each row\ncalifornia_data.loc[:, 'Combined_Score'] = california_data['Total.Verbal'] + california_data['Total.Math']\n\n# Group the filtered DataFrame by 'year' and calculate the average combined score for each year\naverage_combined_score = california_data.groupby('Year')['Combined_Score'].mean()\n\n# Plot the data on a line graph\nplt.figure(figsize=(10, 6))  # Set the size of the figure (width, height)\n\n# Plot the average combined score against the years\nplt.plot(average_combined_score.index, average_combined_score, marker='o', linestyle='-', color='b')\n\n# Add labels and title\nplt.xlabel('Year')\nplt.ylabel('Average Combined Score')\nplt.title('Average Combined Score in California Over the Years')\n\n# Show the plot\nplt.grid(True)  # Add grid lines for better visualization\nplt.tight_layout()  # Adjusts the layout to prevent overlapping of labels\nplt.show()\n\n/tmp/ipykernel_554/619601270.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  california_data.loc[:, 'Combined_Score'] = california_data['Total.Verbal'] + california_data['Total.Math']\n\n\n\n\n\nDespite GPA increasing steadily each year across the nation, the average combined score in California was steadily decreasing and it seems like students were not as effected by the addition of an essay compared to the rest of the nation. This finding could suggest that California students might be better prepared or less impacted by the essay section, possibly due to better educational approaches or preparation methods in the state.\n\n\nAverage Combined Scores in Virginia\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Filter the data for California\ncalifornia_data = df[df['State.Name'] == 'Virginia']\n\n# Calculate the combined score by adding 'Total.Verbal' and 'Total.Math' for each row\ncalifornia_data.loc[:, 'Combined_Score'] = california_data['Total.Verbal'] + california_data['Total.Math']\n\n# Group the filtered DataFrame by 'year' and calculate the average combined score for each year\naverage_combined_score = california_data.groupby('Year')['Combined_Score'].mean()\n\nplt.figure(figsize=(10, 6))  # Set the size of the figure (width, height)\n\nplt.plot(average_combined_score.index, average_combined_score, marker='o', linestyle='-', color='b')\n\nplt.xlabel('Year')\nplt.ylabel('Average Combined Score')\nplt.title('Average Combined Score in Virginia Over the Years')\n\nplt.grid(True)  # Add grid lines for better visualization\nplt.tight_layout()  # Adjusts the layout to prevent overlapping of labels\nplt.show()\n\n/tmp/ipykernel_554/2454308043.py:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  california_data.loc[:, 'Combined_Score'] = california_data['Total.Verbal'] + california_data['Total.Math']\n\n\n\n\n\nUnlike California, the Average Combined Score in Virginia was decreasing after 2006 when they changed the scoring system and another drop was seen after they added the essay section. However, after 2011, there is a steady increase and the average score is higher than the average score in California. This suggests that there is more variance within the state than there are between the states.\n\n\nAverage Combined Scores in 20-40k Income Bracket compared to 80-100k Income Bracket\n\nimport matplotlib.pyplot as plt\n\n# Step 1: Calculate the total number of test-takers in the 20-40k income bracket\ntotal_test_takers_20_40k = df['Family Income.Between 20-40k.Test-takers'].sum()\n\n# Step 2: Calculate the average combined score for the 20-40k income bracket\naverage_combined_score_20_40k = (df['Total.Verbal'] + df['Total.Math']).where(df['Family Income.Between 20-40k.Test-takers'] &gt; 1000).mean()\n\n# Step 3: Calculate the total number of test-takers in the &gt;100k income bracket\ntotal_test_takers_100k = df['Family Income.More than 100k.Test-takers'].sum()\n\n# Step 4: Calculate the average combined score for the &gt;100k income bracket\naverage_combined_score_100k = (df['Total.Verbal'] + df['Total.Math']).where(df['Family Income.More than 100k.Test-takers'] &gt; 1000).mean()\n\n# Step 5: Plot the results\nplt.figure(figsize=(8, 6))\nplt.bar(['20-40k', '&gt;100k'], [average_combined_score_20_40k, average_combined_score_100k], color=['blue', 'green'])\nplt.xlabel('Income Bracket')\nplt.ylabel('Average Combined Score')\nplt.title('Average Combined Scores in 20-40k and &gt;100k Income Brackets')\nplt.show()\n\n\n\n\nSurprisingly, there is not a discrepancy between performance in 20-40k and &gt;100k. This could possible be due to the sample size of data that is collected and how it is mainly higher performing students that are taking the SAT. Furthermore, the average Verbal score does not take into consideration Writing and only the Reading score which can once again explain why there is missing data and thus missing data.\n\n\nCase Analysis\n\nn = 15\nfreqneg = nltk.FreqDist(neg)\nfreqpos = nltk.FreqDist(pos)\n\ncommneg = []\nfor word, freq in freqneg.most_common():\n    commneg.append(word)\n    if len(commneg) == n:\n        break\n\ncommpos = []\nfor word, freq in freqpos.most_common():\n    commpos.append(word)\n    if len(commpos) == n:\n        break\n\nplt.figure(figsize=(15, 6))\n\nplt.subplot(1, 2, 1)\nfor i, word in enumerate(commneg[::-1]):\n    plt.barh(i, freqneg[word], align='center', color='red', alpha=0.7)\n    plt.yticks(range(n), commneg[::-1])\nplt.xlabel('Frequency')\nplt.ylabel('Negative Words')\nplt.title('15 Most Common Negative Words in Supreme Court Affirmative Action Statement')\n\nplt.subplot(1, 2, 2)\nfor i, word in enumerate(commpos[::-1]):\n    plt.barh(i, freqpos[word], align='center', color='green', alpha=0.7)\n    plt.yticks(range(n), commpos[::-1])\nplt.xlabel('Frequency')\nplt.ylabel('Positive Words')\nplt.title('15 Most Common Positive Words in Supreme Court Affirmative Action Statement')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nThe most common negative words were “no”, “limited” and “argued”. The most common positive words were “Fair”, “Justice” and “United”. More investigation will be needed in order to investigate whether these were negative words to describe the decision or the concept of affirmative action. However, it does provide insight into the kind of language that is being used surrounding the topic of affirmative action such as institutional inequities like slavery and war. Thus, it is important to consider historical perspective in discussions related to affirmative action."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]